{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Tagger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UKhQ3rSnuZu15sYwfffi0IvV37CNEy8O",
      "authorship_tag": "ABX9TyM2xiDrUvY02tuf0wWezpcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isunitha98selvan/ner-tagger/blob/main/NER_Tagger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVnxKIp1XyB7",
        "outputId": "66ade775-08dc-4a0b-f71e-b9e304976bb9"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgIONt3AaF94",
        "outputId": "2431bb36-ac74-450e-af9c-0becc8aebfa2"
      },
      "source": [
        "!pip3 install flair"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/a0/a1b41fa2fcb23ff71ba9148af75211dcccc35b256dea821b36e1ee871848/flair-0.7-py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 5.6MB/s \n",
            "\u001b[?25hCollecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/91/77/3f0f53856e86af32b1d3c86652815277f7b5f880002584eb30db115b6df5/bpemb-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.7.0+cu101)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/01/47358efec5396fc80f98273c42cbdfe7aab056252b07884ffcc0f118978f/konoha-4.6.2-py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 21.4MB/s \n",
            "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Collecting sentencepiece<=0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (2.8.1)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/76/a1/05d7f62f956d77b23a640efc650f80ce24483aa2f85a09c03fb64f49e879/Deprecated-1.2.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/e2/3b51c53dffb1e52d9210ebc01f1fb9f2f6eba9b3201fa971fd3946643c71/ftfy-5.8.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.2MB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.2.2)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/a3/8407c1e62d5980188b4acc45ef3d94b933d14a2ebc9ef3505f22cf772570/langdetect-1.0.8.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.7)\n",
            "Collecting transformers<=3.5.1,>=3.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from flair) (4.2.6)\n",
            "Collecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.3.2->flair) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->flair) (0.16.0)\n",
            "Collecting overrides==3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/42/8d/caa729f809ecdf8e76fac3c1ff7d3f0b72c398c9dd8a6919927a30a873b3/overrides-3.0.0.tar.gz\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (3.0.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.12.4)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 32.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<=3.5.1,>=3.5.0->flair) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.11.8)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<=3.5.1,>=3.5.0->flair) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<=3.5.1,>=3.5.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: mpld3, sqlitedict, ftfy, segtok, langdetect, overrides, sacremoses\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp36-none-any.whl size=116677 sha256=02a07f17e1d6f26cd2bd5a7e41b0b29f8b9f710512ae0df63124be6fbfe5928c\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp36-none-any.whl size=14377 sha256=44bdcdad1575114ea369e2ca284ae451d1a2f0fe9e75f329093f0205e4f5789c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.8-cp36-none-any.whl size=45612 sha256=6b252f7f6da956c9e1931ce3136f64dffd3cd216688fb64d8ef77dd8550d5222\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/c0/ef/f28c4da5ac84a4e06ac256ca9182fc34fa57fefffdbc68425b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp36-none-any.whl size=25021 sha256=8dd8221fb01e4c302c631da44b28cd5674377f8e178c85dfcc06e63b6a1d6bc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.8-cp36-none-any.whl size=993195 sha256=8aa416281c8c6983b385651282c9d6fec7c07c31d9cb7d97e8d8bbd5c69a3c68\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/b3/aa/6d99de9f3841d7d3d40a60ea06e6d669e8e5012e6c8b947a57\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.0.0-cp36-none-any.whl size=5669 sha256=ad010cb80abfedb63428efc634609c62a7b4318dd9d3c1a96fe33e511100c8cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/6f/1b/ec/6c71a1eb823df7f850d956b2d8c50a6d49c191e1063d73b9be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=96ad84d069c9d6873046d119c8301ac02dd293f0035dcd1daef206cd5b77a88f\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built mpld3 sqlitedict ftfy segtok langdetect overrides sacremoses\n",
            "Installing collected packages: sentencepiece, bpemb, overrides, konoha, mpld3, sqlitedict, deprecated, ftfy, segtok, langdetect, tokenizers, sacremoses, transformers, janome, flair\n",
            "Successfully installed bpemb-0.3.2 deprecated-1.2.10 flair-0.7 ftfy-5.8 janome-0.4.1 konoha-4.6.2 langdetect-1.0.8 mpld3-0.3 overrides-3.0.0 sacremoses-0.0.43 segtok-1.5.10 sentencepiece-0.1.91 sqlitedict-1.7.0 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBpWuMg7YvhP"
      },
      "source": [
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings\n",
        "from typing import List\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IDKUQHZYyTA",
        "outputId": "1d8528f9-da8d-49c5-aac1-fee488cedaaf"
      },
      "source": [
        "columns = {0:'text' , 1: 'pos', 2: 'tag', 3:'ner'}\n",
        "data_folder = 'gdrive/MyDrive/ner-tagger/data'\n",
        "\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file = 'train_data_new.txt',\n",
        "                              test_file = 'test_data_new.txt',\n",
        "                              dev_file = 'dev_data_new.txt')\n",
        "\n",
        "print(len(corpus.train))\n",
        "print(corpus.train[0].to_tagged_string('ner'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-09 15:16:25,633 Reading data from gdrive/MyDrive/ner-tagger/data\n",
            "2020-12-09 15:16:25,634 Train: gdrive/MyDrive/ner-tagger/data/train_data_new.txt\n",
            "2020-12-09 15:16:25,635 Dev: gdrive/MyDrive/ner-tagger/data/dev_data_new.txt\n",
            "2020-12-09 15:16:25,638 Test: gdrive/MyDrive/ner-tagger/data/test_data_new.txt\n",
            "14392\n",
            "EU <I-ORG> rejects German <I-MISC> call to boycott British <I-MISC> lamb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvB_fuA2a3QV",
        "outputId": "94c392b7-6993-4010-a257-4ed8900a40fb"
      },
      "source": [
        "tag_type = 'ner'\n",
        "\n",
        "tag_dict = corpus.make_tag_dictionary(tag_type=tag_type)\n",
        "\n",
        "embedding_types : List[TokenEmbeddings] = [\n",
        "        WordEmbeddings('glove')\n",
        "        ]\n",
        "embeddings : StackedEmbeddings = StackedEmbeddings(\n",
        "                                 embeddings=embedding_types)\n",
        "\n",
        "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
        "                                       embeddings=embeddings,\n",
        "                                       tag_dictionary=tag_dict,\n",
        "                                       tag_type=tag_type,\n",
        "                                       use_crf=True)\n",
        "\n",
        "print(tagger)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=11, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Cfpi1cnbJF5",
        "outputId": "ef8ba7ec-a951-4116-bb3f-c0a8dda4ee46"
      },
      "source": [
        "trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
        "trainer.train('resources/taggers/example-ner',\n",
        "              learning_rate=0.1,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=50)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-09 15:16:39,532 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,534 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings('glove')\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (rnn): LSTM(100, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=11, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-12-09 15:16:39,536 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,538 Corpus: \"Corpus: 14392 train + 260 dev + 3095 test sentences\"\n",
            "2020-12-09 15:16:39,540 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,543 Parameters:\n",
            "2020-12-09 15:16:39,546  - learning_rate: \"0.1\"\n",
            "2020-12-09 15:16:39,547  - mini_batch_size: \"32\"\n",
            "2020-12-09 15:16:39,549  - patience: \"3\"\n",
            "2020-12-09 15:16:39,551  - anneal_factor: \"0.5\"\n",
            "2020-12-09 15:16:39,552  - max_epochs: \"50\"\n",
            "2020-12-09 15:16:39,555  - shuffle: \"True\"\n",
            "2020-12-09 15:16:39,556  - train_with_dev: \"False\"\n",
            "2020-12-09 15:16:39,558  - batch_growth_annealing: \"False\"\n",
            "2020-12-09 15:16:39,559 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,561 Model training base path: \"resources/taggers/example-ner\"\n",
            "2020-12-09 15:16:39,562 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,564 Device: cuda:0\n",
            "2020-12-09 15:16:39,566 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:39,567 Embeddings storage mode: cpu\n",
            "2020-12-09 15:16:39,570 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:16:48,668 epoch 1 - iter 45/450 - loss 10.16603380 - samples/sec: 158.42 - lr: 0.100000\n",
            "2020-12-09 15:16:57,890 epoch 1 - iter 90/450 - loss 8.22939471 - samples/sec: 156.22 - lr: 0.100000\n",
            "2020-12-09 15:17:06,892 epoch 1 - iter 135/450 - loss 7.37802503 - samples/sec: 160.06 - lr: 0.100000\n",
            "2020-12-09 15:17:16,638 epoch 1 - iter 180/450 - loss 6.76061213 - samples/sec: 147.82 - lr: 0.100000\n",
            "2020-12-09 15:17:25,901 epoch 1 - iter 225/450 - loss 6.35419172 - samples/sec: 155.53 - lr: 0.100000\n",
            "2020-12-09 15:17:34,878 epoch 1 - iter 270/450 - loss 6.04328881 - samples/sec: 160.48 - lr: 0.100000\n",
            "2020-12-09 15:17:46,584 epoch 1 - iter 315/450 - loss 5.80995335 - samples/sec: 123.05 - lr: 0.100000\n",
            "2020-12-09 15:17:55,243 epoch 1 - iter 360/450 - loss 5.60618136 - samples/sec: 166.39 - lr: 0.100000\n",
            "2020-12-09 15:18:03,910 epoch 1 - iter 405/450 - loss 5.43783966 - samples/sec: 166.21 - lr: 0.100000\n",
            "2020-12-09 15:18:12,401 epoch 1 - iter 450/450 - loss 5.28852609 - samples/sec: 169.67 - lr: 0.100000\n",
            "2020-12-09 15:18:12,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:18:12,408 EPOCH 1 done: loss 5.2885 - lr 0.1000000\n",
            "2020-12-09 15:18:13,338 DEV : loss 3.2530415058135986 - score 0.6959\n",
            "2020-12-09 15:18:13,356 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:18:16,066 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:18:23,937 epoch 2 - iter 45/450 - loss 3.95269598 - samples/sec: 183.10 - lr: 0.100000\n",
            "2020-12-09 15:18:31,613 epoch 2 - iter 90/450 - loss 3.92181613 - samples/sec: 187.67 - lr: 0.100000\n",
            "2020-12-09 15:18:39,315 epoch 2 - iter 135/450 - loss 3.86732548 - samples/sec: 187.07 - lr: 0.100000\n",
            "2020-12-09 15:18:47,183 epoch 2 - iter 180/450 - loss 3.72403824 - samples/sec: 183.11 - lr: 0.100000\n",
            "2020-12-09 15:18:55,211 epoch 2 - iter 225/450 - loss 3.68293181 - samples/sec: 179.43 - lr: 0.100000\n",
            "2020-12-09 15:19:03,159 epoch 2 - iter 270/450 - loss 3.62690464 - samples/sec: 181.30 - lr: 0.100000\n",
            "2020-12-09 15:19:10,654 epoch 2 - iter 315/450 - loss 3.58061914 - samples/sec: 192.23 - lr: 0.100000\n",
            "2020-12-09 15:19:18,236 epoch 2 - iter 360/450 - loss 3.54765745 - samples/sec: 190.02 - lr: 0.100000\n",
            "2020-12-09 15:19:26,170 epoch 2 - iter 405/450 - loss 3.50004272 - samples/sec: 181.59 - lr: 0.100000\n",
            "2020-12-09 15:19:33,812 epoch 2 - iter 450/450 - loss 3.45362771 - samples/sec: 188.52 - lr: 0.100000\n",
            "2020-12-09 15:19:33,813 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:19:33,820 EPOCH 2 done: loss 3.4536 - lr 0.1000000\n",
            "2020-12-09 15:19:34,616 DEV : loss 2.5770928859710693 - score 0.7497\n",
            "2020-12-09 15:19:34,633 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:19:37,286 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:19:45,320 epoch 3 - iter 45/450 - loss 3.23659430 - samples/sec: 179.36 - lr: 0.100000\n",
            "2020-12-09 15:19:53,019 epoch 3 - iter 90/450 - loss 3.24269465 - samples/sec: 187.14 - lr: 0.100000\n",
            "2020-12-09 15:20:00,887 epoch 3 - iter 135/450 - loss 3.27926068 - samples/sec: 183.08 - lr: 0.100000\n",
            "2020-12-09 15:20:08,886 epoch 3 - iter 180/450 - loss 3.22839906 - samples/sec: 180.12 - lr: 0.100000\n",
            "2020-12-09 15:20:16,402 epoch 3 - iter 225/450 - loss 3.22975859 - samples/sec: 191.68 - lr: 0.100000\n",
            "2020-12-09 15:20:24,313 epoch 3 - iter 270/450 - loss 3.18131347 - samples/sec: 182.12 - lr: 0.100000\n",
            "2020-12-09 15:20:31,743 epoch 3 - iter 315/450 - loss 3.14869184 - samples/sec: 193.91 - lr: 0.100000\n",
            "2020-12-09 15:20:39,481 epoch 3 - iter 360/450 - loss 3.11052236 - samples/sec: 186.16 - lr: 0.100000\n",
            "2020-12-09 15:20:47,288 epoch 3 - iter 405/450 - loss 3.09499744 - samples/sec: 184.54 - lr: 0.100000\n",
            "2020-12-09 15:20:54,685 epoch 3 - iter 450/450 - loss 3.07064392 - samples/sec: 194.78 - lr: 0.100000\n",
            "2020-12-09 15:20:54,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:20:54,693 EPOCH 3 done: loss 3.0706 - lr 0.1000000\n",
            "2020-12-09 15:20:55,424 DEV : loss 2.1141998767852783 - score 0.8038\n",
            "2020-12-09 15:20:55,440 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:20:58,176 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:21:06,514 epoch 4 - iter 45/450 - loss 2.91726190 - samples/sec: 172.82 - lr: 0.100000\n",
            "2020-12-09 15:21:14,385 epoch 4 - iter 90/450 - loss 2.94375031 - samples/sec: 183.03 - lr: 0.100000\n",
            "2020-12-09 15:21:22,307 epoch 4 - iter 135/450 - loss 2.96625773 - samples/sec: 181.88 - lr: 0.100000\n",
            "2020-12-09 15:21:29,926 epoch 4 - iter 180/450 - loss 2.91122671 - samples/sec: 189.08 - lr: 0.100000\n",
            "2020-12-09 15:21:37,702 epoch 4 - iter 225/450 - loss 2.91720858 - samples/sec: 185.30 - lr: 0.100000\n",
            "2020-12-09 15:21:45,767 epoch 4 - iter 270/450 - loss 2.90386450 - samples/sec: 178.64 - lr: 0.100000\n",
            "2020-12-09 15:21:54,117 epoch 4 - iter 315/450 - loss 2.88064043 - samples/sec: 172.52 - lr: 0.100000\n",
            "2020-12-09 15:22:01,912 epoch 4 - iter 360/450 - loss 2.86133105 - samples/sec: 184.83 - lr: 0.100000\n",
            "2020-12-09 15:22:09,659 epoch 4 - iter 405/450 - loss 2.84584038 - samples/sec: 185.96 - lr: 0.100000\n",
            "2020-12-09 15:22:17,562 epoch 4 - iter 450/450 - loss 2.84241539 - samples/sec: 182.32 - lr: 0.100000\n",
            "2020-12-09 15:22:17,564 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:22:17,570 EPOCH 4 done: loss 2.8424 - lr 0.1000000\n",
            "2020-12-09 15:22:18,336 DEV : loss 2.094987154006958 - score 0.822\n",
            "2020-12-09 15:22:18,350 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:22:21,018 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:22:28,500 epoch 5 - iter 45/450 - loss 2.72666057 - samples/sec: 192.70 - lr: 0.100000\n",
            "2020-12-09 15:22:36,273 epoch 5 - iter 90/450 - loss 2.78293386 - samples/sec: 185.33 - lr: 0.100000\n",
            "2020-12-09 15:22:44,029 epoch 5 - iter 135/450 - loss 2.75654532 - samples/sec: 185.77 - lr: 0.100000\n",
            "2020-12-09 15:22:51,662 epoch 5 - iter 180/450 - loss 2.72263443 - samples/sec: 188.76 - lr: 0.100000\n",
            "2020-12-09 15:22:59,460 epoch 5 - iter 225/450 - loss 2.67400509 - samples/sec: 184.77 - lr: 0.100000\n",
            "2020-12-09 15:23:06,955 epoch 5 - iter 270/450 - loss 2.67422793 - samples/sec: 192.21 - lr: 0.100000\n",
            "2020-12-09 15:23:15,159 epoch 5 - iter 315/450 - loss 2.69517780 - samples/sec: 175.62 - lr: 0.100000\n",
            "2020-12-09 15:23:22,907 epoch 5 - iter 360/450 - loss 2.69093078 - samples/sec: 185.96 - lr: 0.100000\n",
            "2020-12-09 15:23:30,457 epoch 5 - iter 405/450 - loss 2.69517325 - samples/sec: 190.83 - lr: 0.100000\n",
            "2020-12-09 15:23:38,321 epoch 5 - iter 450/450 - loss 2.71326959 - samples/sec: 183.20 - lr: 0.100000\n",
            "2020-12-09 15:23:38,323 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:23:38,329 EPOCH 5 done: loss 2.7133 - lr 0.1000000\n",
            "2020-12-09 15:23:39,020 DEV : loss 1.8457818031311035 - score 0.8509\n",
            "2020-12-09 15:23:39,035 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:23:41,773 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:23:49,493 epoch 6 - iter 45/450 - loss 2.63505303 - samples/sec: 186.71 - lr: 0.100000\n",
            "2020-12-09 15:23:57,364 epoch 6 - iter 90/450 - loss 2.61886716 - samples/sec: 183.05 - lr: 0.100000\n",
            "2020-12-09 15:24:05,016 epoch 6 - iter 135/450 - loss 2.58826761 - samples/sec: 188.28 - lr: 0.100000\n",
            "2020-12-09 15:24:12,494 epoch 6 - iter 180/450 - loss 2.57988100 - samples/sec: 192.67 - lr: 0.100000\n",
            "2020-12-09 15:24:20,186 epoch 6 - iter 225/450 - loss 2.56946717 - samples/sec: 187.30 - lr: 0.100000\n",
            "2020-12-09 15:24:28,276 epoch 6 - iter 270/450 - loss 2.55717946 - samples/sec: 178.08 - lr: 0.100000\n",
            "2020-12-09 15:24:36,161 epoch 6 - iter 315/450 - loss 2.57944723 - samples/sec: 182.71 - lr: 0.100000\n",
            "2020-12-09 15:24:43,897 epoch 6 - iter 360/450 - loss 2.58066034 - samples/sec: 186.25 - lr: 0.100000\n",
            "2020-12-09 15:24:51,845 epoch 6 - iter 405/450 - loss 2.58198059 - samples/sec: 181.27 - lr: 0.100000\n",
            "2020-12-09 15:24:59,637 epoch 6 - iter 450/450 - loss 2.58401693 - samples/sec: 184.94 - lr: 0.100000\n",
            "2020-12-09 15:24:59,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:24:59,644 EPOCH 6 done: loss 2.5840 - lr 0.1000000\n",
            "2020-12-09 15:25:00,333 DEV : loss 1.9226938486099243 - score 0.8475\n",
            "2020-12-09 15:25:00,348 BAD EPOCHS (no improvement): 1\n",
            "2020-12-09 15:25:00,349 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:25:08,517 epoch 7 - iter 45/450 - loss 2.43436571 - samples/sec: 176.42 - lr: 0.100000\n",
            "2020-12-09 15:25:16,399 epoch 7 - iter 90/450 - loss 2.46035727 - samples/sec: 182.78 - lr: 0.100000\n",
            "2020-12-09 15:25:24,158 epoch 7 - iter 135/450 - loss 2.48997261 - samples/sec: 185.67 - lr: 0.100000\n",
            "2020-12-09 15:25:31,920 epoch 7 - iter 180/450 - loss 2.48716509 - samples/sec: 185.62 - lr: 0.100000\n",
            "2020-12-09 15:25:39,801 epoch 7 - iter 225/450 - loss 2.48353214 - samples/sec: 182.80 - lr: 0.100000\n",
            "2020-12-09 15:25:47,222 epoch 7 - iter 270/450 - loss 2.47204769 - samples/sec: 194.14 - lr: 0.100000\n",
            "2020-12-09 15:25:54,946 epoch 7 - iter 315/450 - loss 2.46494455 - samples/sec: 186.52 - lr: 0.100000\n",
            "2020-12-09 15:26:03,202 epoch 7 - iter 360/450 - loss 2.47750956 - samples/sec: 174.49 - lr: 0.100000\n",
            "2020-12-09 15:26:10,835 epoch 7 - iter 405/450 - loss 2.45763527 - samples/sec: 188.74 - lr: 0.100000\n",
            "2020-12-09 15:26:18,521 epoch 7 - iter 450/450 - loss 2.47268591 - samples/sec: 187.46 - lr: 0.100000\n",
            "2020-12-09 15:26:18,522 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:26:18,528 EPOCH 7 done: loss 2.4727 - lr 0.1000000\n",
            "2020-12-09 15:26:19,260 DEV : loss 1.6375597715377808 - score 0.8733\n",
            "2020-12-09 15:26:19,275 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:26:22,009 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:26:29,924 epoch 8 - iter 45/450 - loss 2.45364591 - samples/sec: 182.09 - lr: 0.100000\n",
            "2020-12-09 15:26:37,666 epoch 8 - iter 90/450 - loss 2.49462795 - samples/sec: 186.07 - lr: 0.100000\n",
            "2020-12-09 15:26:45,921 epoch 8 - iter 135/450 - loss 2.46987535 - samples/sec: 174.53 - lr: 0.100000\n",
            "2020-12-09 15:26:54,291 epoch 8 - iter 180/450 - loss 2.44574082 - samples/sec: 172.13 - lr: 0.100000\n",
            "2020-12-09 15:27:02,196 epoch 8 - iter 225/450 - loss 2.44866606 - samples/sec: 182.24 - lr: 0.100000\n",
            "2020-12-09 15:27:09,965 epoch 8 - iter 270/450 - loss 2.46316349 - samples/sec: 185.46 - lr: 0.100000\n",
            "2020-12-09 15:27:17,467 epoch 8 - iter 315/450 - loss 2.46559793 - samples/sec: 192.06 - lr: 0.100000\n",
            "2020-12-09 15:27:25,109 epoch 8 - iter 360/450 - loss 2.43678047 - samples/sec: 188.54 - lr: 0.100000\n",
            "2020-12-09 15:27:32,773 epoch 8 - iter 405/450 - loss 2.44173919 - samples/sec: 187.97 - lr: 0.100000\n",
            "2020-12-09 15:27:40,294 epoch 8 - iter 450/450 - loss 2.42478473 - samples/sec: 191.56 - lr: 0.100000\n",
            "2020-12-09 15:27:40,295 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:27:40,301 EPOCH 8 done: loss 2.4248 - lr 0.1000000\n",
            "2020-12-09 15:27:41,026 DEV : loss 1.7118983268737793 - score 0.8415\n",
            "2020-12-09 15:27:41,043 BAD EPOCHS (no improvement): 1\n",
            "2020-12-09 15:27:41,044 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:27:49,124 epoch 9 - iter 45/450 - loss 2.34987555 - samples/sec: 178.36 - lr: 0.100000\n",
            "2020-12-09 15:27:56,665 epoch 9 - iter 90/450 - loss 2.31543277 - samples/sec: 191.07 - lr: 0.100000\n",
            "2020-12-09 15:28:04,762 epoch 9 - iter 135/450 - loss 2.34032760 - samples/sec: 177.92 - lr: 0.100000\n",
            "2020-12-09 15:28:12,513 epoch 9 - iter 180/450 - loss 2.37611726 - samples/sec: 185.86 - lr: 0.100000\n",
            "2020-12-09 15:28:20,481 epoch 9 - iter 225/450 - loss 2.35471677 - samples/sec: 180.81 - lr: 0.100000\n",
            "2020-12-09 15:28:28,144 epoch 9 - iter 270/450 - loss 2.35937473 - samples/sec: 188.03 - lr: 0.100000\n",
            "2020-12-09 15:28:35,798 epoch 9 - iter 315/450 - loss 2.35993987 - samples/sec: 188.21 - lr: 0.100000\n",
            "2020-12-09 15:28:43,712 epoch 9 - iter 360/450 - loss 2.36470140 - samples/sec: 182.05 - lr: 0.100000\n",
            "2020-12-09 15:28:51,354 epoch 9 - iter 405/450 - loss 2.35038776 - samples/sec: 188.51 - lr: 0.100000\n",
            "2020-12-09 15:28:59,228 epoch 9 - iter 450/450 - loss 2.35166481 - samples/sec: 182.97 - lr: 0.100000\n",
            "2020-12-09 15:28:59,230 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:28:59,238 EPOCH 9 done: loss 2.3517 - lr 0.1000000\n",
            "2020-12-09 15:28:59,934 DEV : loss 1.6937263011932373 - score 0.8793\n",
            "2020-12-09 15:28:59,949 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:29:02,650 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:29:10,724 epoch 10 - iter 45/450 - loss 2.48210735 - samples/sec: 178.48 - lr: 0.100000\n",
            "2020-12-09 15:29:18,407 epoch 10 - iter 90/450 - loss 2.32166541 - samples/sec: 187.53 - lr: 0.100000\n",
            "2020-12-09 15:29:25,864 epoch 10 - iter 135/450 - loss 2.29952396 - samples/sec: 193.19 - lr: 0.100000\n",
            "2020-12-09 15:29:33,383 epoch 10 - iter 180/450 - loss 2.28059612 - samples/sec: 191.61 - lr: 0.100000\n",
            "2020-12-09 15:29:41,246 epoch 10 - iter 225/450 - loss 2.28704482 - samples/sec: 183.21 - lr: 0.100000\n",
            "2020-12-09 15:29:48,972 epoch 10 - iter 270/450 - loss 2.30467239 - samples/sec: 186.49 - lr: 0.100000\n",
            "2020-12-09 15:29:56,415 epoch 10 - iter 315/450 - loss 2.28245541 - samples/sec: 193.55 - lr: 0.100000\n",
            "2020-12-09 15:30:04,348 epoch 10 - iter 360/450 - loss 2.29516927 - samples/sec: 181.60 - lr: 0.100000\n",
            "2020-12-09 15:30:12,142 epoch 10 - iter 405/450 - loss 2.29968002 - samples/sec: 184.87 - lr: 0.100000\n",
            "2020-12-09 15:30:19,526 epoch 10 - iter 450/450 - loss 2.29613263 - samples/sec: 195.11 - lr: 0.100000\n",
            "2020-12-09 15:30:19,527 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:30:19,530 EPOCH 10 done: loss 2.2961 - lr 0.1000000\n",
            "2020-12-09 15:30:20,226 DEV : loss 1.491698980331421 - score 0.8754\n",
            "2020-12-09 15:30:20,250 BAD EPOCHS (no improvement): 1\n",
            "2020-12-09 15:30:20,252 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:30:28,243 epoch 11 - iter 45/450 - loss 2.37126659 - samples/sec: 180.31 - lr: 0.100000\n",
            "2020-12-09 15:30:35,898 epoch 11 - iter 90/450 - loss 2.33998111 - samples/sec: 188.22 - lr: 0.100000\n",
            "2020-12-09 15:30:43,801 epoch 11 - iter 135/450 - loss 2.26736083 - samples/sec: 182.27 - lr: 0.100000\n",
            "2020-12-09 15:30:51,268 epoch 11 - iter 180/450 - loss 2.23741117 - samples/sec: 192.96 - lr: 0.100000\n",
            "2020-12-09 15:30:58,666 epoch 11 - iter 225/450 - loss 2.24387471 - samples/sec: 194.74 - lr: 0.100000\n",
            "2020-12-09 15:31:06,730 epoch 11 - iter 270/450 - loss 2.23593853 - samples/sec: 178.65 - lr: 0.100000\n",
            "2020-12-09 15:31:14,230 epoch 11 - iter 315/450 - loss 2.24126730 - samples/sec: 192.10 - lr: 0.100000\n",
            "2020-12-09 15:31:21,704 epoch 11 - iter 360/450 - loss 2.24876284 - samples/sec: 192.75 - lr: 0.100000\n",
            "2020-12-09 15:31:29,618 epoch 11 - iter 405/450 - loss 2.24964409 - samples/sec: 182.05 - lr: 0.100000\n",
            "2020-12-09 15:31:37,464 epoch 11 - iter 450/450 - loss 2.24159048 - samples/sec: 183.61 - lr: 0.100000\n",
            "2020-12-09 15:31:37,465 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:31:37,468 EPOCH 11 done: loss 2.2416 - lr 0.1000000\n",
            "2020-12-09 15:31:38,150 DEV : loss 1.6069637537002563 - score 0.8744\n",
            "2020-12-09 15:31:38,164 BAD EPOCHS (no improvement): 2\n",
            "2020-12-09 15:31:38,166 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:31:45,911 epoch 12 - iter 45/450 - loss 2.14448806 - samples/sec: 186.07 - lr: 0.100000\n",
            "2020-12-09 15:31:54,276 epoch 12 - iter 90/450 - loss 2.17919182 - samples/sec: 172.22 - lr: 0.100000\n",
            "2020-12-09 15:32:02,048 epoch 12 - iter 135/450 - loss 2.18674010 - samples/sec: 185.36 - lr: 0.100000\n",
            "2020-12-09 15:32:09,722 epoch 12 - iter 180/450 - loss 2.20940021 - samples/sec: 187.76 - lr: 0.100000\n",
            "2020-12-09 15:32:17,287 epoch 12 - iter 225/450 - loss 2.20921181 - samples/sec: 190.43 - lr: 0.100000\n",
            "2020-12-09 15:32:24,521 epoch 12 - iter 270/450 - loss 2.20759668 - samples/sec: 199.18 - lr: 0.100000\n",
            "2020-12-09 15:32:32,022 epoch 12 - iter 315/450 - loss 2.19588198 - samples/sec: 192.08 - lr: 0.100000\n",
            "2020-12-09 15:32:39,764 epoch 12 - iter 360/450 - loss 2.19558763 - samples/sec: 186.08 - lr: 0.100000\n",
            "2020-12-09 15:32:47,186 epoch 12 - iter 405/450 - loss 2.19987250 - samples/sec: 194.10 - lr: 0.100000\n",
            "2020-12-09 15:32:54,732 epoch 12 - iter 450/450 - loss 2.20078559 - samples/sec: 190.94 - lr: 0.100000\n",
            "2020-12-09 15:32:54,733 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:32:54,738 EPOCH 12 done: loss 2.2008 - lr 0.1000000\n",
            "2020-12-09 15:32:55,476 DEV : loss 1.5093754529953003 - score 0.8795\n",
            "2020-12-09 15:32:55,491 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:32:58,081 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:33:05,726 epoch 13 - iter 45/450 - loss 2.19170178 - samples/sec: 188.55 - lr: 0.100000\n",
            "2020-12-09 15:33:12,985 epoch 13 - iter 90/450 - loss 2.14149633 - samples/sec: 198.54 - lr: 0.100000\n",
            "2020-12-09 15:33:20,680 epoch 13 - iter 135/450 - loss 2.15073369 - samples/sec: 187.22 - lr: 0.100000\n",
            "2020-12-09 15:33:28,312 epoch 13 - iter 180/450 - loss 2.17085279 - samples/sec: 188.76 - lr: 0.100000\n",
            "2020-12-09 15:33:35,877 epoch 13 - iter 225/450 - loss 2.17923891 - samples/sec: 190.45 - lr: 0.100000\n",
            "2020-12-09 15:33:44,024 epoch 13 - iter 270/450 - loss 2.16621368 - samples/sec: 176.82 - lr: 0.100000\n",
            "2020-12-09 15:33:52,036 epoch 13 - iter 315/450 - loss 2.17742052 - samples/sec: 179.82 - lr: 0.100000\n",
            "2020-12-09 15:33:59,771 epoch 13 - iter 360/450 - loss 2.16886946 - samples/sec: 186.25 - lr: 0.100000\n",
            "2020-12-09 15:34:07,265 epoch 13 - iter 405/450 - loss 2.16718960 - samples/sec: 192.26 - lr: 0.100000\n",
            "2020-12-09 15:34:15,240 epoch 13 - iter 450/450 - loss 2.14937147 - samples/sec: 180.65 - lr: 0.100000\n",
            "2020-12-09 15:34:15,241 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:34:15,247 EPOCH 13 done: loss 2.1494 - lr 0.1000000\n",
            "2020-12-09 15:34:15,932 DEV : loss 1.470401644706726 - score 0.8788\n",
            "2020-12-09 15:34:15,948 BAD EPOCHS (no improvement): 1\n",
            "2020-12-09 15:34:15,950 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:34:23,473 epoch 14 - iter 45/450 - loss 2.18093775 - samples/sec: 191.64 - lr: 0.100000\n",
            "2020-12-09 15:34:31,297 epoch 14 - iter 90/450 - loss 2.19146559 - samples/sec: 184.14 - lr: 0.100000\n",
            "2020-12-09 15:34:38,811 epoch 14 - iter 135/450 - loss 2.16576355 - samples/sec: 191.75 - lr: 0.100000\n",
            "2020-12-09 15:34:46,066 epoch 14 - iter 180/450 - loss 2.17340180 - samples/sec: 198.57 - lr: 0.100000\n",
            "2020-12-09 15:34:53,687 epoch 14 - iter 225/450 - loss 2.16629818 - samples/sec: 189.05 - lr: 0.100000\n",
            "2020-12-09 15:35:00,931 epoch 14 - iter 270/450 - loss 2.14804539 - samples/sec: 198.86 - lr: 0.100000\n",
            "2020-12-09 15:35:08,468 epoch 14 - iter 315/450 - loss 2.13708993 - samples/sec: 191.17 - lr: 0.100000\n",
            "2020-12-09 15:35:15,842 epoch 14 - iter 360/450 - loss 2.13860126 - samples/sec: 195.37 - lr: 0.100000\n",
            "2020-12-09 15:35:23,984 epoch 14 - iter 405/450 - loss 2.14073108 - samples/sec: 176.93 - lr: 0.100000\n",
            "2020-12-09 15:35:31,890 epoch 14 - iter 450/450 - loss 2.13242492 - samples/sec: 182.23 - lr: 0.100000\n",
            "2020-12-09 15:35:31,892 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:35:31,905 EPOCH 14 done: loss 2.1324 - lr 0.1000000\n",
            "2020-12-09 15:35:32,615 DEV : loss 1.436280369758606 - score 0.8878\n",
            "2020-12-09 15:35:32,631 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:35:35,262 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:35:43,132 epoch 15 - iter 45/450 - loss 2.07010031 - samples/sec: 183.16 - lr: 0.100000\n",
            "2020-12-09 15:35:51,440 epoch 15 - iter 90/450 - loss 2.03539309 - samples/sec: 173.40 - lr: 0.100000\n",
            "2020-12-09 15:35:58,872 epoch 15 - iter 135/450 - loss 2.03622576 - samples/sec: 193.87 - lr: 0.100000\n",
            "2020-12-09 15:36:06,375 epoch 15 - iter 180/450 - loss 2.06895760 - samples/sec: 192.02 - lr: 0.100000\n",
            "2020-12-09 15:36:13,978 epoch 15 - iter 225/450 - loss 2.09969140 - samples/sec: 189.49 - lr: 0.100000\n",
            "2020-12-09 15:36:21,539 epoch 15 - iter 270/450 - loss 2.09665136 - samples/sec: 190.54 - lr: 0.100000\n",
            "2020-12-09 15:36:29,024 epoch 15 - iter 315/450 - loss 2.10094187 - samples/sec: 192.48 - lr: 0.100000\n",
            "2020-12-09 15:36:36,539 epoch 15 - iter 360/450 - loss 2.09276683 - samples/sec: 191.73 - lr: 0.100000\n",
            "2020-12-09 15:36:44,208 epoch 15 - iter 405/450 - loss 2.09398435 - samples/sec: 187.86 - lr: 0.100000\n",
            "2020-12-09 15:36:51,660 epoch 15 - iter 450/450 - loss 2.10303403 - samples/sec: 193.42 - lr: 0.100000\n",
            "2020-12-09 15:36:51,661 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:36:51,669 EPOCH 15 done: loss 2.1030 - lr 0.1000000\n",
            "2020-12-09 15:36:52,412 DEV : loss 1.6286399364471436 - score 0.8903\n",
            "2020-12-09 15:36:52,423 BAD EPOCHS (no improvement): 0\n",
            "saving best model\n",
            "2020-12-09 15:36:55,079 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:37:02,485 epoch 16 - iter 45/450 - loss 2.09093533 - samples/sec: 194.57 - lr: 0.100000\n",
            "2020-12-09 15:37:09,936 epoch 16 - iter 90/450 - loss 1.99383321 - samples/sec: 193.35 - lr: 0.100000\n",
            "2020-12-09 15:37:12,559 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:37:12,561 Exiting from training early.\n",
            "2020-12-09 15:37:12,562 Saving model ...\n",
            "2020-12-09 15:37:15,268 Done.\n",
            "2020-12-09 15:37:15,270 ----------------------------------------------------------------------------------------------------\n",
            "2020-12-09 15:37:15,274 Testing using best model ...\n",
            "2020-12-09 15:37:15,278 loading file resources/taggers/example-ner/best-model.pt\n",
            "2020-12-09 15:37:23,654 0.9120\t0.8517\t0.8808\n",
            "2020-12-09 15:37:23,655 \n",
            "Results:\n",
            "- F1-score (micro) 0.8808\n",
            "- F1-score (macro) 0.8575\n",
            "\n",
            "By class:\n",
            "LOC        tp: 1524 - fp: 130 - fn: 94 - precision: 0.9214 - recall: 0.9419 - f1-score: 0.9315\n",
            "MISC       tp: 533 - fp: 69 - fn: 252 - precision: 0.8854 - recall: 0.6790 - f1-score: 0.7686\n",
            "ORG        tp: 919 - fp: 149 - fn: 329 - precision: 0.8605 - recall: 0.7364 - f1-score: 0.7936\n",
            "PER        tp: 1614 - fp: 95 - fn: 124 - precision: 0.9444 - recall: 0.9287 - f1-score: 0.9365\n",
            "2020-12-09 15:37:23,656 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [3.2530415058135986,\n",
              "  2.5770928859710693,\n",
              "  2.1141998767852783,\n",
              "  2.094987154006958,\n",
              "  1.8457818031311035,\n",
              "  1.9226938486099243,\n",
              "  1.6375597715377808,\n",
              "  1.7118983268737793,\n",
              "  1.6937263011932373,\n",
              "  1.491698980331421,\n",
              "  1.6069637537002563,\n",
              "  1.5093754529953003,\n",
              "  1.470401644706726,\n",
              "  1.436280369758606,\n",
              "  1.6286399364471436],\n",
              " 'dev_score_history': [0.6959459459459459,\n",
              "  0.7497360084477297,\n",
              "  0.8038379530916844,\n",
              "  0.8220338983050848,\n",
              "  0.8508863399374348,\n",
              "  0.847457627118644,\n",
              "  0.8733264675592174,\n",
              "  0.8414755732801595,\n",
              "  0.8792569659442724,\n",
              "  0.8753799392097265,\n",
              "  0.874361593462717,\n",
              "  0.8795180722891567,\n",
              "  0.8787878787878787,\n",
              "  0.8877654196157735,\n",
              "  0.8902564102564102],\n",
              " 'test_score': 0.8808290155440414,\n",
              " 'train_loss_history': [5.28852608733707,\n",
              "  3.4536277074284025,\n",
              "  3.070643917189704,\n",
              "  2.8424153889550103,\n",
              "  2.713269590801663,\n",
              "  2.5840169331762524,\n",
              "  2.4726859095361498,\n",
              "  2.4247847276263768,\n",
              "  2.3516648128297595,\n",
              "  2.2961326277256013,\n",
              "  2.2415904765658907,\n",
              "  2.200785585774316,\n",
              "  2.149371471405029,\n",
              "  2.132424924373627,\n",
              "  2.1030340298016865]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}